{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Optimisation (groupe 6) - Benjamin Piet & Damien Capéraa\n",
    "\n",
    "## 2. Etude et resolution numerique\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Notre problème d'optimisation est le suivant : \n",
    "$$\\min_{C^Tp - d}\\frac{1}{2}p^TAp-b^Tp$$\\\n",
    "On note $f(p)=\\frac{1}{2}p^TAp-b^Tp$ la fonction coût et $c(p)=C^Tp-d$ les contraintes.\n",
    "Dans la suite, on notera $x = p$ pour éviter toute confusion entre la variable des prix $p$ et les directions de descente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etude du problème\n",
    "La fonction f est **fortement convexe** car la matrice $A$ est symétrique definie positive. Pour le démontrer, on peut déjà remarquer que $A$ est symétrique puis utiliser le théorème d'éuivalence $A \\in S_n^{++}(\\mathbb{R}) \\Leftrightarrow A \\in S_n(\\mathbb{R}) \\, et \\, Sp(A) \\subset \\mathbb{R}^{+*}$ et calculer les valeurs propres de A avec Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des valeurs propres de A : [0.02753417 0.00496583 3.0825     0.0405    ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[3.0825, 0, 0, 0], [0, 0.0405, 0, 0], [0, 0, 0.0271, -0.0031], \\\n",
    "     [0, 0, -0.0031, 0.0054]])\n",
    "valeurs_propres = np.linalg.eig(A)[0]\n",
    "print(f\"Liste des valeurs propres de A : {valeurs_propres}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les valeurs propres de $A$ étant strictement positives, elle est symétrique définie positive. Par conséquent, la fonction de coût quadratique f est convexe.\\\n",
    "De plus, l'ensemble de recherche est convexe, car les contraintes sont toutes affines.\n",
    "On a donc **l'existence d'un unique minimum global**.\\\n",
    "\\\n",
    "Le conditionnement du problème vaut :\n",
    "$$K(A) = \\frac{max(Sp(A))}{min(Sp(A))} \\approx 620,7$$\n",
    "ce qui est assez élevé. On doit donc s'attendre à ce qu'une petite erreur dans les données du problème engendre une grande erreur dans la solution estimée numériquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choix d'une méthode de résolution\n",
    "* Les contraintes de notre problème sont des contraintes d'inégalités. Nous proposons d'utiliser un algorithme de recherche du point selle du Lagrangien. En effet, un point $(x^*, \\lambda ^*)$ est un point selle du Lagrangien si et seulement si $x^*$ est solution du problème d'otpimisation.\n",
    "* En outre, si l'on suppose que les contraintes actives en $x^*$ sont qualifiées, alors la convexite de $f$ garantit l'existence d'un point selle du Lagrangien grâce au théorème 29 du cours.\n",
    "* Finalement, nous proposons d'implémenter **l'algorithme d'Uzawa**, qui repose bien sur le concept de dualité du problème (p.38 du polycopié) : à partir de $x^0 \\in \\mathbb{R}^4$, $\\lambda^0 \\in \\mathbb{R}^7$, $\\rho \\in \\mathbb{R}^+$ quelconques, on note $\\mathbb{R}^7 \\ni \\lambda \\mapsto P(\\lambda) \\in (\\mathbb{R}^+)^7$ la projection sur $(\\mathbb{R}^+)^7$, itérer : \n",
    "    * résoudre $\\min_{x \\in \\mathbb{R}^4} \\mathcal{L}(x, \\lambda ^k)$, on note $x^{k+1}$ la solution ;\n",
    "    * $\\lambda ^{k+1} = P(\\lambda ^k + \\rho c(x^{k+1}))$.\n",
    "* Pour la partie minimisation, nous allons utiliser deux algorithmes : un algorithme de gradient à pas optimal, en déterminant un pas à chaque itération à l'aide des conditions de Wolfe, et un algorithme de gradient à pas fixe. Nous déterminerons la valeur du pas fixe en observant les pas optimaux choisis avec les condition de Wolfe.\n",
    "* Pour la partie maximisation, nous gardons la méthode proposée dans l'algorithme qui s'apparente à une montée de gradient à pas fixe.\n",
    "* En parallèle, nous allons utiliser la fonction `minimize` du module `scipy.optimize` de Python pour pouvoir apprécier l'efficacité de nos algorithmes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en place des fonctions et valeurs numériques\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[3.0825, 0, 0, 0], [0, 0.0405, 0, 0], [0, 0, 0.0271, -0.0031], \\\n",
    "    [0, 0, -0.0031, 0.0054]])\n",
    "b = np.array([[2671], [135], [103], [19]])\n",
    "C = np.array([[-0.0401, -0.1326, 1.5413, 0.0, 0.0, 0.0, 0.0160], \\\n",
    "    [-0.0162, -0.0004, 0.0, 0.0203, 0.0, 0.0, 0.0004], \\\n",
    "    [-0.0039, -0.0034, 0.0, 0.0, 0.0136, -0.0016, 0.0005], \\\n",
    "    [0.0002, 0.0006, 0.0, 0.0, -0.0015, 0.0027, 0.0002]])\n",
    "d = np.array([[-92.6], [-29.0], [2671], [135], [103], [19], [10]])\n",
    "\n",
    "def f(p):\n",
    "    return float(0.5 * np.matmul(p.T, np.matmul(A, p)) - np.dot(b.T, p))\n",
    "\n",
    "def c(p):\n",
    "    return np.matmul(C.T, p) - d\n",
    "\n",
    "def grad_f(p):\n",
    "    return np.matmul(A, p) - b\n",
    "\n",
    "def grad_c(p):\n",
    "    return C\n",
    "\n",
    "lambda0 = np.ones((7, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimation de la solution avec `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy.optimize.minimize...\n",
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 107, function evaluations: 745, CG iterations: 171, optimality: 1.87e-05, constraint violation: 0.00e+00, execution time: 0.13 s.\n",
      "Solution estimée : [ 420.23259847 4025.00827192 2774.95770729 1393.98131029]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import LinearConstraint\n",
    "import numpy as np\n",
    "\n",
    "# Réécriture des contraites sous une forme compréhensible par scipy.optimize.minimize :\n",
    "linear_constraint = LinearConstraint([[-0.0401, -0.0162, -0.0039, 0.0002], \\\n",
    "    [-0.1326, -0.0004, -0.0034, 0.0006], [1.5413, 0, 0, 0], \\\n",
    "    [0, 0.0203, 0, 0], [0, 0, 0.0136, -0.0015], \\\n",
    "    [0, 0, -0.0016, 0.0027], [0.0160, 0.0004, 0.0005, 0.0002]], \\\n",
    "    [-np.inf]*7, [-92.6, 29.0, 2671, 135, 103, 19, 10])\n",
    "\n",
    "x0 = np.ones((4,))\n",
    "print(\"scipy.optimize.minimize...\")\n",
    "res = minimize(f, x0, method ='trust-constr', constraints=[linear_constraint], \\\n",
    "    options={'verbose': 1})\n",
    "print(f\"Solution estimée : {res.x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve donc un prix en €/tonnes optimal de :\n",
    "* **420** pour le **lait**\n",
    "* **4025** pour le **beurre**\n",
    "* **2775** pour le **gouda**\n",
    "* **1394** pour le **edam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui correspond aux quantités :\n",
    "* 2023 tonnes pour le lait\n",
    "* 53.3 tonnes pour le beurre\n",
    "* 67.4 tonnes pour le gouda\n",
    "* 19.9 tonnes pour l'edam\n",
    "\\\n",
    "**Remarque** : Nous ne sommes pas totalement sûrs au niveau des unités."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait, après avoir testé avec la fonction `scipy.optimize` pour avoir une idée de la solution attendue, nous avons trouvé que l'algorithme à pas fixe semble mieux converger que celui à pas de Wolfe, et en moins de temps (même si le nombre d'iteration est bien plus grand, le temps d'execution est plus faible).\\\n",
    "Nous mettons tous de même les deux algorithmes, mais nous vous conseillons de ne pas lancer celui à pas de Wolfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minimisation avec algorithme de gradient à pas fixe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uzawa fixed step...\n",
      "Nombre d'iterations : 537076\n",
      "lambdak :  [[ 4036.34636983]\n",
      " [    0.        ]\n",
      " [    0.        ]\n",
      " [    0.        ]\n",
      " [    0.        ]\n",
      " [    0.        ]\n",
      " [95112.14898624]]\n",
      "Temps d'exécution : 21.10329270362854\n",
      "x_fixed_step : [[ 425.32463559]\n",
      " [4008.48593851]\n",
      " [2792.62037364]\n",
      " [1449.69225136]]\n",
      "c(x_fixed_step) : [[ 5.72890218e-03]\n",
      " [-3.76265350e+01]\n",
      " [-2.01544714e+03]\n",
      " [-5.36277354e+01]\n",
      " [-6.71949013e+01]\n",
      " [-1.95540235e+01]\n",
      " [ 9.48371819e-02]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def uzawa_fixed_step(fun, grad_fun, c, grad_c, x0, l, rho, lambda0, max_iter = 1000000, epsilon_grad_L = 1e-3):\n",
    "    ''' epsilon_grad_L est un paramètre qui fixe une borne supérieure\n",
    "    du gradient du Lagrangien en guise de condition d'arrêt.\n",
    "    l est le pas fixe de descente (selon x).\n",
    "    rho est le pas fixe de montée (selon lambda).\n",
    "    '''\n",
    "    k = 0\n",
    "    xk = x0\n",
    "    lambdak = lambda0\n",
    "    grad_Lagrangien_xk = grad_fun(xk) + np.matmul(grad_c(xk), lambdak)\n",
    "    while ((k < max_iter) and (np.linalg.norm(grad_Lagrangien_xk) > epsilon_grad_L)):\n",
    "        grad_Lagrangien_xk = grad_fun(xk) + np.matmul(grad_c(xk), lambdak)\n",
    "        pk = -grad_Lagrangien_xk\n",
    "        xk = xk + l*pk\n",
    "        lambdak = np.array([[max(0, lambdak[i, 0] + rho*c(xk)[i, 0])] for i in range(7)]) # projection sur R+^7\n",
    "        k = k + 1\n",
    "    print(f\"Nombre d'iterations : {k}\")\n",
    "    print(f\"lambdak : \", lambdak)\n",
    "    return xk\n",
    "\n",
    "x0 = np.ones((4, 1))\n",
    "print(\"Uzawa fixed step...\")\n",
    "start_time = time.time()\n",
    "x_fixed_step = uzawa_fixed_step(f, grad_f, c, grad_c, x0, 0.5, 0.1, lambda0)\n",
    "''' Note: après avoir testé l'algorithme avec conditions de Wolfe, on a un pas au début \n",
    "qui est au alentours de 0.5, puis des oscillations qui dépassent rarement l'unité. \n",
    "C'est pour cela que nous avons choisi un pas de 0.5 pour l'algorithme à pas fixe.'''\n",
    "print(f\"Temps d'exécution : {time.time() - start_time}\")\n",
    "print(f\"x_fixed_step : {x_fixed_step}\")\n",
    "print(f\"c(x_fixed_step) : {c(x_fixed_step)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minimisation vec algorithme de gradient à pas variable\n",
    "*Remarque* : cet algorithme met beaucoup de temps à s'exécuter (environ 2 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uzawa wolfe step...\n",
      "Nombre d'iterations :  385222\n",
      "lk :  2.048\n",
      "Temps d'exécution : 107.36856865882874\n",
      "x_wolfe_step : [[ 437.94582898]\n",
      " [3967.55025756]\n",
      " [2836.31660775]\n",
      " [1587.31018024]]\n",
      "c(x_wolfe_step) : [[ 1.98853514e-02]\n",
      " [-3.93497274e+01]\n",
      " [-1.99599409e+03]\n",
      " [-5.44587298e+01]\n",
      " [-6.68070594e+01]\n",
      " [-1.92523691e+01]\n",
      " [ 3.29773707e-01]]\n"
     ]
    }
   ],
   "source": [
    "def wolfe_step(fun, grad_fun, xk, pk, c1 = 0.25, c2 = 0.75, M = 1000):\n",
    "    ''' Calcul du pas optimal selon les conditions de Wolfe.'''\n",
    "    l_moins = 0\n",
    "    l_plus = 0\n",
    "    f_xk = fun(xk)\n",
    "    grad_f_xk = grad_fun(xk)\n",
    "    li = 0.001\n",
    "    i = 0\n",
    "    while(i < M):\n",
    "        if (fun(xk + li*pk) > (f_xk + c1*li*np.dot(grad_f_xk.T, pk))):\n",
    "            # Condition d'Armijo pas respectée : on diminue le pas.\n",
    "            l_plus = li\n",
    "            li = (l_moins + l_plus)/2.0\n",
    "        else:\n",
    "            if (np.dot(grad_fun(xk + li*pk).T, pk) < c2*np.dot(grad_f_xk.T, pk)):\n",
    "                # Condition de courbure pas respectée : on augmente le pas.\n",
    "                l_moins = li\n",
    "                if (l_plus == 0):\n",
    "                    li = 2*li\n",
    "                else:\n",
    "                    li = (l_moins + l_plus)/2.0\n",
    "            else:\n",
    "                return li\n",
    "        i = i + 1\n",
    "    return li\n",
    "\n",
    "\n",
    "def uzawa_wolfe_step(fun, grad_fun, c, grad_c, x0, rho, lambda0, max_iter = 1000000, epsilon_grad_L = 1e-3):\n",
    "    k = 0\n",
    "    xk = x0\n",
    "    lambdak = lambda0\n",
    "    grad_Lagrangienk_xk = grad_fun(xk) + np.matmul(grad_c(xk), lambdak)\n",
    "    while ((k < max_iter) and (np.linalg.norm(grad_Lagrangienk_xk) > epsilon_grad_L)):\n",
    "        Lagrangienk = lambda x : fun(x) + np.dot(lambdak.T, c(x))\n",
    "        grad_Lagrangienk = lambda x : grad_fun(x) + np.matmul(grad_c(x), lambdak)\n",
    "        grad_Lagrangienk_xk = grad_Lagrangienk(xk)\n",
    "        pk = -grad_Lagrangienk_xk\n",
    "        lk = wolfe_step(Lagrangienk, grad_Lagrangienk, xk, pk)\n",
    "        xk = xk + lk*pk\n",
    "        lambdak = np.array([[max(0, lambdak[i, 0] + rho*c(xk)[i, 0])] for i in range(7)]) # projection sur R+^7\n",
    "        k = k + 1\n",
    "    print(f\"Nombre d'iterations : {k}\")\n",
    "    print(f\"lambdak : {lambdak}\")\n",
    "    return xk\n",
    "\n",
    "print(\"Uzawa wolfe step...\")\n",
    "start_time = time.time()\n",
    "x_wolfe_step = uzawa_wolfe_step(f, grad_f, c, grad_c, x0, 0.1, lambda0)\n",
    "print(f\"Temps d'exécution : {time.time() - start_time}\")\n",
    "print(f\"x_wolfe_step : {x_wolfe_step}\")\n",
    "print(f\"c(x_wolfe_step) : {c(x_wolfe_step)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires sur toutes les méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                         | Solution renvoyée | Nombre d'itérations | Temps d'exécution (s)|\n",
    "|:-----------------------:|:-----------------:|:-------------------:|:--------------------:|\n",
    "| scipy.optimize.minimize |$\\begin{pmatrix} 420&4025&2775&1394\\\\ \\end{pmatrix}$|107|0.13|\n",
    "| Uzawa pas fixe          |$\\begin{pmatrix} 425&4008&2793&1450\\\\ \\end{pmatrix}$|537 076|21|\n",
    "| Uzawa pas optimal       |$\\begin{pmatrix} 438&3968&2836&1587\\\\ \\end{pmatrix}$|385 222|107|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fait fonctionné les deux algorithmes d'Uzawa avec les mêmes critères d'arrêt (nombre d'itération et norme du gradient du Lagrangien inférieure à $10^{-3}$), nous pouvons donc comparer leurs performances.\n",
    "* Le module `scipy.optimize` offre clairement la meilleure performance, sur tous les points, et sans comparaison avec les performances des deux autres algorithmes.\n",
    "* L'algorithme d'Uzawa avec descente de gradient à pas optimal donne des performances décevantes sur le temps d'exécution. Cela est probablement dû aux calculs générés par la recherche du pas optimal sous les conditions de Wolfe : cela rajoute plusieurs dizaines de calculs par itération dans la boucle d'Uzawa. En outre, la solution qu'il propose semble plus éloignée de la solution réelle que l'algorithme d'Uzawa à pas fixe (en regardant composante par composante, cela est assez visible). Il n'obtient de meilleure performance que sur le nombre d'exécution, avec un écart d'environ 150 000 itérations, ce qui n'est pas négligeable. Cependant, ce nombre de tient pas compte des itérations faites dans la boucle de recherche du pas optimal, ce qui évacue de fait un nombre très important de calculs.\n",
    "* L'algorithme d'Uzawa à pas fixe obtient des performances meilleures que celui à pas variable, et c'est assez surprenant. Nous pouvons supposer que notre code comporte des erreurs qui rendent l'algorithme à pas optimal moins efficace que ce qu'il devrait être."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Etude avancée\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Tout d'abord, les trois méthodes nous montrent que les multiplicateurs de Lagrange au point solution du problème $x^*$ sont nuls pour toutes les contraintes sauf la 1 et la 7, qui sont donc les deux seules contraintes actives. En utilisant le théorème Karush-Kuhn-Tucker (KKT), on a l'égalité suivante où $\\lambda_2 = \\lambda_3 = \\lambda_4 = \\lambda_5 = \\lambda_6 = 0$ :\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla f(x^*) &= - \\sum_{i=1}^7 \\lambda_i \\nabla c_i(x^*) \\\\\n",
    "Ap^* - b &= - C\\lambda \\\\\n",
    "p^* &= A^{-1}(b - C\\lambda) \\\\\n",
    "p^* &= A^{-1}\n",
    "\\begin{pmatrix}\n",
    "2671 + 0.0401\\lambda_1 - 0.0160\\lambda_7 \\\\\n",
    "135 + 0.0162\\lambda_1 - 0.0004\\lambda_7 \\\\\n",
    "103 + 0.0038\\lambda_1 - 0.0005\\lambda_7 \\\\\n",
    "19 - 0.0002\\lambda_1 - 0.0002\\lambda_7 \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Question 2\n",
    "On pourra supposer qu'une petite variation des élasticités-prix engendre une petite variation des coefficients devant $\\lambda_1$ et $\\lambda_7$, et vérifie en intégrant cette solution dans l'expression des contraintes $c$ que les contraintes 1 et 7 sont toujours actives avec l'hypothèse $\\lambda_1 > 0$ et $\\lambda_7 > 0$ (non dégénérescence de la solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexe\n",
    "\n",
    "Avant de nous orienter vers l'algorithme d'Uzawa, nous avons tenté d'utiliser un algorithme des contraintes actives (p.39 du polycopié). Cet algorithme requiert en particulier de caluler les multiplicateurs de Lagrange pour chaque contrainte à chaque itération. C'est précisément cette étape que nous n'avons pas réussi à implémenter, et notre algorithme n'a malheureusement jamais abouti. Nous mettons néanmoins ici le code et les explications que nous avions produits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 2 (a) de l'algorithme : résolution du problème d'otpimisation sous contraintes d'égalité** \\\n",
    "L'étape consiste à résoudre $\\displaystyle \\min_{c_i^Tp = 0, i \\in W^k} \\frac{1}{2}p^TGp + (Gx^k + d)^Tp$.\n",
    "On introduit le Lagrangien du problème $\\mathcal{L}(p, \\lambda) = \\frac{1}{2}p^TGp + (Gx^k + d)^Tp + \\lambda^TD^Tp$ ou $D$ est la matrice composée des colonnes $c_i$ de C pour $i \\in W^k$.\n",
    "Un point stationnaire du Lagrangien sans contraintes est un point stationnaire de la fonction coût sous contraintes : on cherche donc le point $(p^*, \\lambda^*)$ qui annule les deux dérivées partielles de $\\mathcal{L}$.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial\\lambda}(p^*, \\lambda^*) &= 0 = D^Tp \\\\\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial p}(p^*, \\lambda^*) &= 0 = Ap + (Ax^k + b) + D\\lambda \\\\\n",
    "\\end{align}$$\n",
    "On réécrit le problème sous forme matricielle car c'est la formulation qui peut être exploitée avec la fonction numpy `np.linalg.solve`\n",
    "$$\n",
    "\\begin{pmatrix} D^T&0 \\\\\n",
    "A&D\\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} p \\\\\n",
    "\\lambda \\\\\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix} 0 \\\\\n",
    "-Ax^k - b \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithme des contraintes actives\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[3.0825, 0, 0, 0], [0, 0.0405, 0, 0], [0, 0, 0.0271, -0.0031], \\\n",
    "     [0, 0, -0.0031, 0.0054]])\n",
    "b = np.array([[2671], [135], [103], [19]])\n",
    "C = np.array([[-0.0401, -0.0162, -0.0039, 0.0002], \\\n",
    "    [-0.1326, -0.0004, -0.0034, 0.0006], [1.5413, 0, 0, 0], \\\n",
    "    [0, 0.0203, 0, 0], [0, 0, 0.0136, -0.0015], \\\n",
    "    [0, 0, -0.0016, 0.0027], [0.0160, 0.0004, 0.0005, 0.0002]]).transpose()\n",
    "d = np.array([[-92.6], [-29.0], [2671], [135], [103], [19], [10]])\n",
    "eps = 1e-8 # paramètre donnant la valeur maximale des composantes\n",
    "# de la direction pk pour que pk ne soit pas considérée comme nulle.\n",
    "\n",
    "def f(p):\n",
    "    return float(0.5 * np.matmul(p.transpose(), np.matmul(A, p)) - np.dot(b.transpose(), p))\n",
    "\n",
    "def c(p):\n",
    "    return np.matmul(C.transpose(), p) - d\n",
    "\n",
    "\n",
    "def xk_is_solution(xk, Wk):\n",
    "    '''\n",
    "    Etape 1 de l'algorithme des contraintes actives.\n",
    "    Détermine, grâce aux conditions KKT, si xk est une solution du problème\n",
    "    d'optimisation restreint aux contraintes contenues dans Wk.\n",
    "    '''\n",
    "    CC = C[:, Wk]\n",
    "    dd = d[Wk, :]\n",
    "    rg = np.linalg.matrix_rank(CC)\n",
    "    if rg == len(Wk):\n",
    "        # Les contraintes actives sont qualifiées\n",
    "        # Conditions de relâchement\n",
    "        Wk_systeme = Wk.copy()\n",
    "        for i, c_i in enumerate([CC[:, j] for j in range(len(Wk))]):\n",
    "            if np.dot(c_i, xk) -  dd[i, 0] != 0:\n",
    "                # Lambda_i = 0 : on retire la contrainte Wk_systeme[i]\n",
    "                del Wk_systeme[Wk_systeme.index(Wk[i])]\n",
    "        Lambda = np.zeros((len(Wk), 1))\n",
    "        print(Wk_systeme)\n",
    "        if len(Wk_systeme) != 0:\n",
    "            CC_systeme = C[:, Wk_systeme]\n",
    "            dd_systeme = d[Wk_systeme, :]\n",
    "            Lambda_systeme = np.linalg.solve(CC_systeme.transpose(), dd_systeme)\n",
    "            for j in Wk:\n",
    "                if j in Wk_systeme:\n",
    "                    Lambda[Wk.index(j), 0] = Lambda_systeme[Wk_systeme.index(j), 0]\n",
    "        return all([Lambda[i, 0] > 0 for i in range(len(Wk))]), Lambda\n",
    "    else:\n",
    "        # Les contraintes actives ne sont pas qualifiées\n",
    "        return False, None\n",
    "\n",
    "W0 = [0, 1, 2, 3] # arbitraire mais permet de n'avoir qu'un point de départ possible\n",
    "# car le système à résoudre contient 4 équations pour 4 inconnues.\n",
    "# Recherche de p0 où ces 4 contraintes sont actives\n",
    "CC = C[:, W0]\n",
    "dd = d[W0, :]\n",
    "x0 = np.linalg.solve(CC.transpose(), dd)\n",
    "\n",
    "def contraintes():\n",
    "    xk = x0\n",
    "    Wk = W0\n",
    "    while True:\n",
    "        if xk_is_solution(xk, Wk)[0]:\n",
    "            return xk, Wk\n",
    "        # (a)\n",
    "        '''\n",
    "        L'étape (a) consiste à résoudre un problème d'optimisation sous\n",
    "        contraintes d'égalité. On cherche alors (p*, Lambda*) point stationnaire\n",
    "        du lagrangien associé. Cette recherche, comme présenté dans le notebook,\n",
    "        aboutit à la résolution d'un système linéaire.\n",
    "        '''\n",
    "        D = C[:, Wk]\n",
    "        E_ligne_0 = np.concatenate((D.transpose(), np.zeros((D.shape[1], D.shape[1]))), axis=1)\n",
    "        E_ligne_1 = np.concatenate((A, D), axis=1)\n",
    "        E = np.concatenate((E_ligne_0, E_ligne_1), axis=0)\n",
    "        F = np.concatenate((np.zeros((D.shape[1], 1)), -np.matmul(A, xk) + b), axis=0)\n",
    "        X = np.linalg.solve(E, F)\n",
    "        pk = X[0:4, :]\n",
    "        if any([abs(pk[i, 0]) > eps for i in range(4)]):\n",
    "            # (b) : pk != 0\n",
    "            W_barre = [i for i in range(7) if i not in Wk]\n",
    "            L, indices = [], []\n",
    "            for i in W_barre:\n",
    "                c_i = C[:,i]\n",
    "                if np.dot(c_i, pk) > 0:\n",
    "                    L.append((d[i, 0] - np.dot(c_i, xk))/np.dot(c_i, pk))\n",
    "                    indices.append(i)\n",
    "            if L != []:\n",
    "                alphak = min(1, min(L))\n",
    "            else:\n",
    "                alphak = 1\n",
    "            xk = xk + alphak*pk\n",
    "            if alphak < 1:\n",
    "                j = indices[L.index(min(L))]\n",
    "                Wk.append(j)\n",
    "        else:\n",
    "            # (c) ! pk = 0\n",
    "            booleen, Lambda = xk_is_solution(xk, Wk)\n",
    "            if booleen:\n",
    "                return xk, Wk\n",
    "            Lambda = Lambda.tolist()\n",
    "            c = Lambda.index(min(Lambda))\n",
    "            del Wk[c]\n",
    "    return xk, Wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 3]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a2be22a118b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontraintes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-7cf1e956408b>\u001b[0m in \u001b[0;36mcontraintes\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mWk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mxk_is_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# (a)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-7cf1e956408b>\u001b[0m in \u001b[0;36mxk_is_solution\u001b[1;34m(xk, Wk)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mCC_systeme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWk_systeme\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mdd_systeme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWk_systeme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mLambda_systeme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCC_systeme\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdd_systeme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mWk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mWk_systeme\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assertNdSquareness\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assertFinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "contraintes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
